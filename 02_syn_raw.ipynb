{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accredited-orange",
   "metadata": {},
   "source": [
    "This notebook explores the use of synthetic data for training and validating LightGBM and RF algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "processed-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accompanied-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "corrected-mineral",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_map = {'Larix decidua': 0,\n",
    " 'Pinus sylvestris': 1,\n",
    " 'Broadleaved trees': 2,\n",
    " 'Picea abies': 3,\n",
    " 'Pinus mugo': 4,\n",
    " 'Pinus cembra': 5,\n",
    " 'Abies alba': 6}\n",
    " # reverse the dictionary\n",
    "value_map = {v: k for k, v in name_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ready-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all features\n",
    "years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
    "bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12', 'ndvi']\n",
    "DATA_PATH = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec5f3e",
   "metadata": {},
   "source": [
    "Model training and prediction using K-Fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a4a8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for year in years:\n",
    "    yearly_results = {}\n",
    "    \n",
    "    # Load synthetic data for training\n",
    "    train_df = pd.read_csv(DATA_PATH + year + \"_syn_raw.csv\", index_col=0, low_memory=False)\n",
    "    train_df.columns = [\"band\", \"date\", *[int(x) for x in train_df.columns[2:]]]\n",
    "    y = train_df.T.pop(\"class\")[2:].astype(int)\n",
    "    train_df = train_df.drop(\"class\")\n",
    "    train_df.date = pd.to_datetime(train_df.date)\n",
    "    train_df = train_df.groupby([\"band\", \"date\"]).mean()\n",
    "    train_df = train_df.loc[bands].fillna(0)    \n",
    "\n",
    "    # Load raw data for testing\n",
    "    raw_df = pd.read_csv(DATA_PATH + year + \"_raw.csv\", index_col=0, low_memory=False)\n",
    "    raw_df.columns = [\"band\", \"date\", *[int(x) for x in raw_df.columns[2:]]]\n",
    "    raw_df = raw_df.drop(\"class\")\n",
    "    raw_df.date = pd.to_datetime(raw_df.date)\n",
    "    raw_df = raw_df.groupby([\"band\", \"date\"]).mean()\n",
    "    raw_df = raw_df.loc[bands]\n",
    "\n",
    "    # Initialize K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store metrics for each fold\n",
    "    lgbm_syn_acc = []\n",
    "    lgbm_syn_f1 = []\n",
    "    rf_syn_acc = []\n",
    "    rf_syn_f1 = []\n",
    "\n",
    "    # Perform k-fold cross validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df.T)):\n",
    "        # Prepare training data\n",
    "        X_train = train_df.loc[raw_df.index].T.iloc[train_idx].values\n",
    "        y_train = y[train_idx]\n",
    "        X_val = train_df.loc[raw_df.index].T.iloc[val_idx].values\n",
    "        y_val = y[val_idx]\n",
    "\n",
    "        # Get unique classes for LightGBM\n",
    "        y_train_unique = np.unique(y_train)\n",
    "\n",
    "        # Train LightGBM\n",
    "        model_lgbm = lgb.LGBMClassifier(\n",
    "            objective='multiclass',\n",
    "            num_class=len(y_train_unique),\n",
    "            metric='multi_logloss',\n",
    "            verbose=-1\n",
    "        )\n",
    "        model_lgbm.fit(X_train, y_train)\n",
    "\n",
    "        # Train Random Forest\n",
    "        model_rf = RandomForestClassifier(n_estimators=1000)\n",
    "        model_rf.fit(X_train, y_train)\n",
    "\n",
    "        # Test on synthetic validation data\n",
    "        y_pred_lgbm_syn = model_lgbm.predict(X_val)\n",
    "        y_pred_rf_syn = model_rf.predict(X_val)\n",
    "\n",
    "        # Calculate metrics for LightGBM\n",
    "        lgbm_syn_acc.append(100 * metrics.accuracy_score(y_val, y_pred_lgbm_syn))\n",
    "        lgbm_syn_f1.append(100 * metrics.f1_score(y_val, y_pred_lgbm_syn, average='weighted'))\n",
    "\n",
    "        # Calculate metrics for Random Forest\n",
    "        rf_syn_acc.append(100 * metrics.accuracy_score(y_val, y_pred_rf_syn))\n",
    "        rf_syn_f1.append(100 * metrics.f1_score(y_val, y_pred_rf_syn, average='weighted'))\n",
    "\n",
    "    # Calculate mean metrics for the year\n",
    "    yearly_results = {\n",
    "        'lgbm_syn': [\n",
    "            np.mean(lgbm_syn_acc),\n",
    "            np.mean(lgbm_syn_f1)\n",
    "        ],\n",
    "        'rf_syn': [\n",
    "            np.mean(rf_syn_acc),\n",
    "            np.mean(rf_syn_f1)\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    results[year] = yearly_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a022fb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean metrics across all years:\n",
      "                               Year   Accuracy         F1\n",
      "Model        Test_Data_Type                              \n",
      "LightGBM     Raw             2021.0  58.201875  51.915017\n",
      "             Synthetic       2021.0  88.703806  88.513925\n",
      "RandomForest Raw             2021.0  41.577496  26.890437\n",
      "             Synthetic       2021.0  83.706564  83.208715\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with metrics for each model and data type\n",
    "metrics_data = {\n",
    "    'Model': [],\n",
    "    'Data_Type': [],\n",
    "    'Year': [],\n",
    "    'Accuracy': [],\n",
    "    'F1': []\n",
    "}\n",
    "\n",
    "for year in years:\n",
    "    for model in ['lgbm', 'rf']:\n",
    "        for data_type in ['syn', 'raw']:\n",
    "            key = f'{model}_{data_type}'\n",
    "            metrics_data['Model'].append('LightGBM' if model == 'lgbm' else 'RandomForest')\n",
    "            metrics_data['Data_Type'].append('Synthetic' if data_type == 'syn' else 'Raw')\n",
    "            metrics_data['Year'].append(int(year))\n",
    "            metrics_data['Accuracy'].append(results[year][key][0])\n",
    "            metrics_data['F1'].append(results[year][key][1])\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "df_metrics.columns = ['Model', 'Test_Data_Type', 'Year', 'Accuracy', 'F1']\n",
    "# Save to CSV\n",
    "df_metrics.to_csv('syn_raw_metrics.csv')\n",
    "\n",
    "# Display mean metrics across years\n",
    "print(\"\\nMean metrics across all years:\")\n",
    "print(df_metrics.groupby(['Model', 'Test_Data_Type']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b13d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean metrics across all years:\n",
    "                               Year   Accuracy         F1\n",
    "Model        Test_Data_Type                              \n",
    "LightGBM     Raw             2020.5  54.504505  46.342181\n",
    "             Synthetic       2020.5  88.339768  88.127918\n",
    "RandomForest Raw             2020.5  42.458172  28.462128\n",
    "             Synthetic       2020.5  83.951094  83.294282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "discrete-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data for all years\n",
    "\n",
    "all_results = {}\n",
    "for year in years:\n",
    "    # Load raw data\n",
    "    raw_df = pd.read_csv(DATA_PATH + year + \"_raw.csv\", index_col=0, low_memory=False)\n",
    "    raw_df.columns = [\"band\", \"date\", *[int(x) for x in raw_df.columns[2:]]]\n",
    "    y = raw_df.T.pop(\"class\")[2:].astype(int)\n",
    "    raw_df = raw_df.drop(\"class\")\n",
    "    raw_df.date = pd.to_datetime(raw_df.date)\n",
    "    raw_df = raw_df.groupby([\"band\", \"date\"]).mean()\n",
    "    raw_df = raw_df.loc[bands]\n",
    "\n",
    "    # Initialize K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Store metrics for each fold\n",
    "    lgbm_acc = []\n",
    "    lgbm_f1 = []\n",
    "\n",
    "    # Perform k-fold cross validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(raw_df.T)):    \n",
    "        # Prepare training data\n",
    "        X_train = raw_df.T.iloc[train_idx].values\n",
    "        X_val = raw_df.T.iloc[val_idx].values\n",
    "        y_train = y[train_idx]\n",
    "        y_val = y[val_idx]\n",
    "        \n",
    "        # Set up the LightGBM model\n",
    "        model_lgbm = lgb.LGBMClassifier(\n",
    "            objective='multiclass',\n",
    "            num_class=len(np.unique(y)),\n",
    "            metric='multi_logloss',\n",
    "            verbose=-1\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        model_lgbm.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model_lgbm.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = 100 * metrics.accuracy_score(y_val, y_pred)\n",
    "        f1 = 100 * metrics.f1_score(y_val, y_pred, average='weighted')\n",
    "        \n",
    "        lgbm_acc.append(acc)\n",
    "        lgbm_f1.append(f1)\n",
    "    \n",
    "    # Store results for this year\n",
    "    all_results[year] = {'F1': np.mean(lgbm_f1), 'OA': np.mean(lgbm_acc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbfed0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1    90.613855\n",
      "OA    90.667402\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with F1 and OA for all years\n",
    "df_metrics = pd.DataFrame(all_results).T\n",
    "df_metrics.columns = ['F1', 'OA']\n",
    "df_metrics.index.name = 'Year'\n",
    "df_metrics.to_csv('full_ts_lightGBM_metrics.csv')\n",
    "print(df_metrics.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1    91.132073\n",
    "OA    91.196911\n",
    "dtype: float64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
