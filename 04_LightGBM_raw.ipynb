{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accredited-orange",
   "metadata": {},
   "source": [
    "This notebook explores the use synthetic data and LightGBM algorithm for forest stand classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "processed-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "accompanied-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "corrected-mineral",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_map = {'Larix decidua': 0,\n",
    " 'Pinus sylvestris': 1,\n",
    " 'Broadleaved trees': 2,\n",
    " 'Picea abies': 3,\n",
    " 'Pinus mugo': 4,\n",
    " 'Pinus cembra': 5,\n",
    " 'Abies alba': 6}\n",
    " # reverse the dictionary\n",
    "value_map = {v: k for k, v in name_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ready-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all features\n",
    "years = [\"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
    "bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B11', 'B12', 'ndvi']\n",
    "DATA_PATH = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec5f3e",
   "metadata": {},
   "source": [
    "Model training and prediction using K-Fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "discrete-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data for all years\n",
    "all_results = {}\n",
    "for year in years:\n",
    "    # Load raw data\n",
    "    raw_df = pd.read_csv(DATA_PATH + year + \"_raw.csv\", index_col=0, low_memory=False)\n",
    "    raw_df.columns = [\"band\", \"date\", *[int(x) for x in raw_df.columns[2:]]]\n",
    "    y = raw_df.T.pop(\"class\")[2:].astype(int)\n",
    "    raw_df = raw_df.drop(\"class\")\n",
    "    raw_df.date = pd.to_datetime(raw_df.date)\n",
    "    raw_df = raw_df.groupby([\"band\", \"date\"]).mean()\n",
    "    raw_df = raw_df.loc[bands]\n",
    "\n",
    "    # Initialize K-fold\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Store metrics for each fold\n",
    "    lgbm_acc = []\n",
    "    lgbm_f1 = []\n",
    "\n",
    "    # Perform k-fold cross validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(raw_df.T)):    \n",
    "        # Prepare training data\n",
    "        X_train = raw_df.T.iloc[train_idx].values\n",
    "        X_val = raw_df.T.iloc[val_idx].values\n",
    "        y_train = y[train_idx]\n",
    "        y_val = y[val_idx]\n",
    "        \n",
    "        # Set up the LightGBM model\n",
    "        model_lgbm = lgb.LGBMClassifier(\n",
    "            objective='multiclass',\n",
    "            num_class=len(np.unique(y)),\n",
    "            metric='multi_logloss',\n",
    "            verbose=-1\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        model_lgbm.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model_lgbm.predict(X_val)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = 100 * metrics.accuracy_score(y_val, y_pred)\n",
    "        f1 = 100 * metrics.f1_score(y_val, y_pred, average='weighted')\n",
    "        \n",
    "        lgbm_acc.append(acc)\n",
    "        lgbm_f1.append(f1)\n",
    "    \n",
    "    # Store results for this year\n",
    "    all_results[year] = {'F1': np.mean(lgbm_f1), 'OA': np.mean(lgbm_acc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbfed0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1    90.613855\n",
      "OA    90.667402\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with F1 and OA for all years\n",
    "df_metrics = pd.DataFrame(all_results).T\n",
    "df_metrics.columns = ['F1', 'OA']\n",
    "df_metrics.index.name = 'Year'\n",
    "df_metrics.to_csv('full_ts_lightGBM_metrics.csv')\n",
    "print(df_metrics.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde6335",
   "metadata": {},
   "outputs": [],
   "source": [
    "F1    91.132073\n",
    "OA    91.196911\n",
    "dtype: float64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
